{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pyreadr\n",
    "import seaborn as sns\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(file_url: str, file_directory: str, file_name: str) -> str:\n",
    "    directory = os.path.join(os.path.abspath(os.curdir), file_directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    file = os.path.join(directory, file_name)\n",
    "    if not os.path.isfile(file):\n",
    "        urllib.request.urlretrieve(file_url, file)\n",
    "    \n",
    "    return file\n",
    "\n",
    "def convert_dataset(original_path: str, destination_path: str) -> str:\n",
    "    if not os.path.isfile(destination_path):\n",
    "        result = pyreadr.read_r(original_path)\n",
    "        df = result['df']\n",
    "\n",
    "        df.to_csv(destination_path, index=True)\n",
    "    \n",
    "    return destination_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_URL = 'https://github.com/yaleemmlc/admissionprediction/raw/master/Results/5v_cleandf.RData'\n",
    "FILE_PATH = 'Datasets'\n",
    "FILE_NAME = 'Results.rdata'\n",
    "\n",
    "# Downloads the Original Dataset (RData File)\n",
    "DATASET_RDATA_PATH = download_dataset(DATASET_URL, FILE_PATH, FILE_NAME)\n",
    "\n",
    "# Converts the RData File to a New CSV File\n",
    "DATASET_CSV_PATH = convert_dataset(DATASET_RDATA_PATH, DATASET_RDATA_PATH.replace('.rdata', '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(DATASET_CSV_PATH)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina las columnas donde todos sus elementos sean iguales\n",
    "columns_to_remove = df.columns[df.n_unique() == 1]\n",
    "df_witout_nunique = df.drop(columns=columns_to_remove)\n",
    "df_witout_nunique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significantColumns = ['cc_chestpain', 'cc_breathingdifficulty', 'cc_syncope', 'cc_unresponsive', 'cc_seizure-newonset', 'cc_seizure-priorhxof', 'cc_seizures', 'cc_bleeding/bruising', 'cc_hyperglycemia', 'cc_hypertension', 'cc_hypotension', 'cc_strokealert', 'cc_overdose-accidental', 'cc_overdose-intentional', 'cc_suicidal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If any of the significant columns are on true, automatically has the flag of emergency\n",
    "df_witout_nunique = df_witout_nunique.to_pandas()\n",
    "df_witout_nunique['emergency_flag_column'] = df_witout_nunique[significantColumns].any(axis=1)\n",
    "\n",
    "print(df_witout_nunique['emergency_flag_column'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "df_converted = df_witout_nunique.copy()\n",
    "\n",
    "# Inicializar el codificador de etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Identificar las variables categóricas\n",
    "categorical_columns = []\n",
    "for column in df_converted.columns:\n",
    "    # Verificar si la columna es de tipo 'object' o 'category'\n",
    "    if df_converted[column].dtype == 'object' or df_converted[column].dtype == 'category' :  \n",
    "        categorical_columns.append(column)\n",
    "\n",
    "# Convertir las variables categóricas usando LabelEncoder\n",
    "for column in categorical_columns:\n",
    "    df_converted[column] = label_encoder.fit_transform(df_converted[column])\n",
    "\n",
    "print(df_converted['gender'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsWithNan = df_converted.isna().any().pipe(lambda x: x.index[x])\n",
    "print(len(columnsWithNan))\n",
    "\n",
    "# Reemplazo los valores nulos con -999. Se podría intentar en una proxima iteracion con algo como col.mode()[0] o valores significativos reales\n",
    "df_filled = df_converted.apply(lambda col: col.fillna(-999))\n",
    "\n",
    "newColumnsWithNan = df_filled.isna().any().pipe(lambda x: x.index[x])\n",
    "print(len(newColumnsWithNan))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del modelo\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# División de datos\n",
    "X = df_filled.drop(columns=['emergency_flag_column'])\n",
    "y = df_filled['emergency_flag_column']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación del modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "TP = confusion[1, 1]\n",
    "FP = confusion[0, 1]\n",
    "TN = confusion[0, 0]\n",
    "FN = confusion[1, 0]\n",
    "\n",
    "print(f\"Verdaderos Positivos: {str(TP)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación de variables categóricas\n",
    "df_encoded = pd.get_dummies(df_witout_nunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Manejo de valores nulos\n",
    "imputer = SimpleImputer(strategy='most_frequent')  \n",
    "df_without_null = imputer.fit_transform(df_witout_nunique)\n",
    "print(df_without_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con las características y las etiquetas codificadas\n",
    "df_plot = X.copy()\n",
    "df_plot['emergency_flag'] = y\n",
    "\n",
    "# Graficar la distribución de las clases\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='emergency_flag', data=df_plot)\n",
    "plt.title('Distribución de Clases')\n",
    "plt.xlabel('Clase')\n",
    "plt.ylabel('Conteo')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
